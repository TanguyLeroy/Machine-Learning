{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chargement des données ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter,defaultdict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from statistics import stdev\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['<x>', '<y>','<z>','<t>','gesture', 'subject', 'iter'])\n",
    "\n",
    "for subject in range(1,11):\n",
    "    for number in range(0,10):\n",
    "        for iteration in range(1,11):\n",
    "            filename = 'Domain1_csv/Subject'+str(subject)+'-'+str(number)+'-'+str(iteration)+'.csv'\n",
    "            file = pd.read_csv(filename)\n",
    "            file['gesture'] = number\n",
    "            file['subject'] = subject\n",
    "            file['iter'] = iteration\n",
    "            df = pd.concat([df, file])\n",
    "df.columns = ['x', 'y', 'z', 't', 'gesture', 'subject', 'iter']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recherche de coordonnées moyenne par geste\n",
    "grouped = df.groupby(['gesture', 'iter'])\n",
    "sequence_lengths = grouped.size().reset_index(name='length')\n",
    "mean_lengths = sequence_lengths.groupby('gesture')['length'].mean().reset_index()\n",
    "mean_lengths.columns = ['Chiffre', 'Frames moyennes']\n",
    "\n",
    "# Affichage  graphique\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(mean_lengths[\"Chiffre\"], mean_lengths[\"Frames moyennes\"], color=\"mediumseagreen\")\n",
    "plt.title(\"Nombre moyen de coordonnée par chiffre\")\n",
    "plt.xlabel(\"Chiffre\")\n",
    "plt.ylabel(\"Nombre moyen de coordonées\")\n",
    "plt.xticks(mean_lengths[\"Chiffre\"])\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# recherche de durée moyenne par geste\n",
    "durations = df.groupby(['gesture', 'iter'])['t'].agg(lambda x: x.max() - x.min()).reset_index(name='duration')\n",
    "mean_durations = durations.groupby('gesture')['duration'].mean()\n",
    "print(\"Durée moyenne des gestes (en secondes) par chiffre :\")\n",
    "for gesture, mean_dur in mean_durations.items():\n",
    "    print(f\"Chiffre {gesture} : {mean_dur:.2f} s\")\n",
    "\n",
    "# statistique par geste \n",
    "stats = durations.groupby('gesture')['duration'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(stats)\n",
    "mean_coords_user = df.groupby(['subject', 'gesture'])[['x', 'y', 'z']].mean().reset_index()\n",
    "mean_coords_global = df.groupby('gesture')[['x', 'y', 'z']].mean().reset_index()\n",
    "mean_coords_global = mean_coords_global.rename(columns={'x':'x_global', 'y':'y_global', 'z':'z_global'})\n",
    "merged = pd.merge(mean_coords_user, mean_coords_global, on='gesture')\n",
    "merged['dist_to_global'] = np.sqrt((merged['x'] - merged['x_global'])**2 +(merged['y'] - merged['y_global'])**2 +(merged['z'] - merged['z_global'])**2)\n",
    "pivot = merged.pivot(index='subject', columns='gesture', values='dist_to_global')\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".3f\", cmap='Blues')\n",
    "plt.title(\"Distance des moyennes de chaque utilisateur à la moyenne globale par chiffre\")\n",
    "plt.xlabel(\"Chiffre\")\n",
    "plt.ylabel(\"Utilisateur\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#affichage geste en 3d\n",
    "subdf = df.loc[(df['gesture'] == 0) & (df['subject'] == 10) & (df['iter'] == 1)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(subdf['x'], subdf['y'], subdf['z'], c='r', marker='o')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de standardisation\n",
    "def standardize_gesture(df_group):\n",
    "    df = df_group.copy()\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        df[f'{axis}_std'] = (df[axis] - df[axis].mean()) / df[axis].std()\n",
    "    return df\n",
    "df = df.groupby(['subject', 'gesture', 'iter'], group_keys=False).apply(standardize_gesture)\n",
    "#df = df.groupby(['gesture'], group_keys=False).apply(standardize_gesture)  #par geste uniquement\n",
    "\n",
    "# creation rang du temps 't' dans chaque groupe\n",
    "df['t_rank'] = df.groupby(['subject', 'gesture', 'iter'])['t'].rank()\n",
    "\n",
    "# Afficher les données normalisées d'une trajectoire en 3D\n",
    "subdf = df.loc[(df['gesture'] == 0) & (df['subject'] == 10) & (df['iter'] == 1)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(subdf['x_std'], subdf['y_std'], subdf['z_std'], c='r', marker='o')\n",
    "print(df.describe().transpose())\n",
    "df.to_csv('df.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_creation_iterout(df, iter_out=10):\n",
    "    # Séparation des données en test et train selon l'itération\n",
    "    test_df = df[df[\"iter\"] == iter_out]\n",
    "    train_df = df[df[\"iter\"] != iter_out]\n",
    "\n",
    "    train_groups = train_df.groupby([\"gesture\", \"subject\", \"iter\"])\n",
    "    test_groups = test_df.groupby([\"gesture\", \"subject\", \"iter\"])\n",
    "\n",
    "    coord_dict_train = {}\n",
    "    for (gesture, subject, _), group in train_groups:\n",
    "        coords = group[[\"x_std\", \"y_std\", \"z_std\"]].values.tolist()\n",
    "        coord_dict_train.setdefault(gesture, []).append(coords)\n",
    "\n",
    "    coord_dict_test = {}\n",
    "    for (gesture, subject, _), group in test_groups:\n",
    "        coords = group[[\"x_std\", \"y_std\", \"z_std\"]].values.tolist()\n",
    "        coord_dict_test.setdefault(gesture, []).append(coords)\n",
    "    return coord_dict_train, coord_dict_test\n",
    "\n",
    "\n",
    "def dict_creation_userout(df, subj_out):\n",
    "    # Filtrage du sujet test\n",
    "    test_df = df[df[\"subject\"] == subj_out]\n",
    "    test_df = test_df[test_df[\"iter\"] <= 10]\n",
    "    train_df = df[df[\"subject\"] != subj_out]\n",
    "\n",
    "    train_groups = train_df.groupby([\"gesture\", \"subject\", \"iter\"])\n",
    "    test_groups = test_df.groupby([\"gesture\", \"subject\", \"iter\"])\n",
    "\n",
    "    coord_dict_train = {}\n",
    "    for (gesture, subject, _), group in train_groups:\n",
    "        coords = group[[\"x_std\", \"y_std\", \"z_std\"]].values.tolist()\n",
    "        coord_dict_train.setdefault(gesture, []).append(coords)\n",
    "\n",
    "    coord_dict_test = {}\n",
    "    for (gesture, subject, _), group in test_groups:\n",
    "        coords = group[[\"x_std\", \"y_std\", \"z_std\"]].values.tolist()\n",
    "        coord_dict_test.setdefault(gesture, []).append(coords)\n",
    "    return coord_dict_train, coord_dict_test\n",
    "\n",
    "def convert_coord_dict_to_xy(DictFunc, df, iter_out):\n",
    "#transfo les dicos pour les modeles complexes\n",
    "    full_dict = DictFunc(df)\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "    for gesture in full_dict:\n",
    "        for subject in full_dict[gesture]:\n",
    "            for iteration in full_dict[gesture][subject]:\n",
    "                coords = full_dict[gesture][subject][iteration]\n",
    "\n",
    "                if DictFunc.__name__ == \"dict_creation_iterout\" and iteration == iter_out:\n",
    "                    X_test.append(coords)\n",
    "                    y_test.append(gesture)\n",
    "                elif DictFunc.__name__ == \"dict_creation_userout\" and subject == iter_out:\n",
    "                    X_test.append(coords)\n",
    "                    y_test.append(gesture)\n",
    "                else:\n",
    "                    X_train.append(coords)\n",
    "                    y_train.append(gesture)\n",
    "\n",
    "    return (np.array(X_train), np.array(y_train),np.array(X_test), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Euclidienne 3D\n",
    "def eucl_dist(list1, list2):\n",
    "    return np.sqrt((list1[0] - list2[0])**2 + (list1[1] - list2[1])**2 + (list1[2] - list2[2])**2)\n",
    "\n",
    "# Distance DTW\n",
    "def dtw_dist(list1, list2):\n",
    "    n = len(list1)\n",
    "    m = len(list2)\n",
    "    dtw_matrix = np.full((n+1, m+1), np.inf)\n",
    "    dtw_matrix[0,0] = 0\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        for j in range(1,m+1):\n",
    "            cost = eucl_dist(list1[i-1], list2[j-1])\n",
    "            last_min = min(dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "\n",
    "    return dtw_matrix[n,m]\n",
    "\n",
    "# KNN\n",
    "def knn_dtw_predict_verbose(reference_seq, train_dict, k=3):\n",
    "    distances = []\n",
    "\n",
    "    for gesture, sequences in train_dict.items():\n",
    "        for seq in sequences:\n",
    "            dist = dtw_dist(reference_seq, seq)\n",
    "            distances.append((gesture, dist))\n",
    "\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    k_nearest_neighbors = distances[:k]\n",
    "\n",
    "    #print(f\"\\nTop {k} voisins les plus proches (label, distance) :\")\n",
    "    #for i, (gesture, dist) in enumerate(k_nearest_neighbors):\n",
    "        #print(f\"  {i+1}. {gesture} — Distance DTW = {dist:.2f}\")\n",
    "\n",
    "    gestures = [gesture for gesture, _ in k_nearest_neighbors]\n",
    "    vote_counts = Counter(gestures)\n",
    "\n",
    "    #print(\"\\nVotes par classe :\")\n",
    "    #for gesture, count in vote_counts.items():\n",
    "        #print(f\"  {gesture} : {count} vote(s)\")\n",
    "\n",
    "    predicted_gesture = vote_counts.most_common(1)[0][0]\n",
    "    return predicted_gesture\n",
    "\n",
    "# MODELE LSTM\n",
    "class LSTMpredict:\n",
    "    model = None\n",
    "    df = None\n",
    "    iter_out = None\n",
    "    DictFunc = None\n",
    "\n",
    "    @staticmethod\n",
    "    def create_model(input_shape=(100, 3), num_classes=10):\n",
    "        model = models.Sequential([\n",
    "            layers.LSTM(64, return_sequences=True, dropout=0.2, input_shape=input_shape),\n",
    "            layers.LSTM(64, dropout=0.3),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def predict(cls, seq):\n",
    "        if cls.model is None:\n",
    "            df = cls.df\n",
    "            iter_out = cls.iter_out\n",
    "            DictFunc = cls.DictFunc\n",
    "\n",
    "            train_dict, _ = DictFunc(df, iter_out)\n",
    "\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "\n",
    "            for gesture, sequences in train_dict.items():\n",
    "                for s in sequences:\n",
    "                    X_train.append(s)\n",
    "                    y_train.append(gesture)\n",
    "\n",
    "            X_train = np.array(X_train, dtype=np.float32)\n",
    "            y_train = np.array(y_train, dtype=np.int32)\n",
    "\n",
    "            num_classes = len(set(y_train))\n",
    "            model = cls.create_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=num_classes)\n",
    "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "            cls.model = model\n",
    "\n",
    "        seq = np.expand_dims(np.array(seq, dtype=np.float32), axis=0)  # (1, 100, 3)\n",
    "        probs = cls.model.predict(seq, verbose=0)\n",
    "        return int(np.argmax(probs, axis=1)[0])\n",
    "\n",
    "# MODELE CNN\n",
    "class CNNpredict:\n",
    "    model = None\n",
    "    df = None\n",
    "    iter_out = None\n",
    "    DictFunc = None\n",
    "\n",
    "    @staticmethod\n",
    "    def build_model(input_shape, num_classes):\n",
    "        model = Sequential([\n",
    "            Conv1D(64, 3, activation='relu', input_shape=input_shape),\n",
    "            MaxPooling1D(2),\n",
    "            Dropout(0.3),\n",
    "            Conv1D(128, 3, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(seq):\n",
    "        # Initialisation du modèle à la première prédiction\n",
    "        if CNNpredict.model is None:\n",
    "            df = CNNpredict.df\n",
    "            iter_out = CNNpredict.iter_out\n",
    "            DictFunc = CNNpredict.DictFunc\n",
    "\n",
    "            train_dict, _ = DictFunc(df, iter_out)\n",
    "\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "\n",
    "            for gesture, sequences in train_dict.items():\n",
    "                for s in sequences:\n",
    "                    X_train.append(s)\n",
    "                    y_train.append(gesture)\n",
    "\n",
    "            X_train = np.array(X_train)\n",
    "            y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "\n",
    "            model = CNNpredict.build_model(X_train.shape[1:], 10)\n",
    "            model.fit(X_train, y_train_cat, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "            CNNpredict.model = model\n",
    "\n",
    "        # Prédiction\n",
    "        input_tensor = np.expand_dims(seq, axis=0)  # shape (1, 100, 3)\n",
    "        y_pred = CNNpredict.model.predict(input_tensor, verbose=0)\n",
    "        return np.argmax(y_pred, axis=1)[0]\n",
    "\n",
    "# MODELE FEATURE\n",
    "def xgboost_feature_predict(coord_dict_train, coord_dict_test):\n",
    "    def dict_to_features(coord_dict):\n",
    "        X, y = [], []\n",
    "        for gesture, sequences in coord_dict.items():\n",
    "            for seq in sequences:\n",
    "                if len(seq) < 5:\n",
    "                    continue\n",
    "                if not isinstance(seq, np.ndarray):\n",
    "                    seq = np.array(seq)\n",
    "                feat = extract_features(seq)\n",
    "                X.append(feat)\n",
    "                y.append(gesture)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X_train, y_train = dict_to_features(coord_dict_train)\n",
    "    X_test, y_test = dict_to_features(coord_dict_test)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    param = {\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        #'n_estimators': 300,\n",
    "        'objective': 'multi:softmax',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'lambda': 1.0,\n",
    "        'alpha': 0.5,\n",
    "        'num_class': len(np.unique(y_train))\n",
    "    }\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    bst = xgb.train(param, dtrain, num_boost_round=300)\n",
    "\n",
    "    y_pred = bst.predict(dtest)\n",
    "    return y_test, y_pred\n",
    "\n",
    "def extract_features(sequence):\n",
    "    features = []\n",
    "\n",
    "    for i in range(3):  # x, y, z\n",
    "        axis = sequence[:, i]\n",
    "        features.extend([\n",
    "            np.mean(axis), np.std(axis), np.min(axis), np.max(axis), np.median(axis),\n",
    "            np.percentile(axis, 25), np.percentile(axis, 75)\n",
    "        ])\n",
    "        fft_vals = np.abs(np.fft.fft(axis))[:10]\n",
    "        features.extend(fft_vals)\n",
    "\n",
    "    velocity = np.diff(sequence, axis=0)\n",
    "    acceleration = np.diff(velocity, axis=0)\n",
    "    for v in [velocity, acceleration]:\n",
    "        norms = np.linalg.norm(v, axis=1)\n",
    "        features.extend([np.mean(norms), np.std(norms), np.max(norms), np.median(norms)])\n",
    "\n",
    "    distance = np.sum(np.linalg.norm(velocity, axis=1))\n",
    "    direction = sequence[-1] - sequence[0]\n",
    "    angle = np.arccos(np.clip(np.dot(direction, [1, 0, 0]) / (np.linalg.norm(direction) + 1e-6), -1, 1))\n",
    "    features.extend([distance, angle])\n",
    "\n",
    "    for i in range(1, len(sequence) - 1):\n",
    "        v1 = sequence[i] - sequence[i - 1]\n",
    "        v2 = sequence[i + 1] - sequence[i]\n",
    "        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "        features.append(np.arccos(np.clip(cos_angle, -1, 1)))\n",
    "\n",
    "    features.extend([np.mean(features[-(len(sequence) - 2):]), np.std(features[-(len(sequence) - 2):])])\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "PREF_XGB_CLASSES = {0, 2, 8, 1}\n",
    "PREF_CNN_CLASSES = {3, 4, 6}\n",
    "\n",
    "# MODELE COMBINE\n",
    "def combined_predict_algo(seq, coord_dict_train, full_dict_test=None):\n",
    "    if full_dict_test is not None and combined_predict_algo.xgb_preds is None:\n",
    "        _, combined_predict_algo.xgb_preds = xgboost_feature_predict(coord_dict_train, full_dict_test)\n",
    "        combined_predict_algo.xgb_iter = 0\n",
    "    xgb_pred = combined_predict_algo.xgb_preds[combined_predict_algo.xgb_iter]\n",
    "    combined_predict_algo.xgb_iter += 1\n",
    "\n",
    "    cnn_pred = CNNpredict.predict(seq)\n",
    "\n",
    "    if xgb_pred == cnn_pred:\n",
    "        return xgb_pred\n",
    "    elif xgb_pred in [0, 2, 8]:\n",
    "        return xgb_pred\n",
    "    elif xgb_pred == 6:\n",
    "        return cnn_pred\n",
    "    else:\n",
    "        return cnn_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from statistics import stdev\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def testmodel(DictCreationFunc, AlgoFunc, df, loop_range=10, k=3, title=None, save_figs=False):\n",
    "    total_true = []\n",
    "    total_pred = []\n",
    "    all_iteration_accuracies = []\n",
    "    all_top_errors = []\n",
    "    erreurs_importantes = []\n",
    "\n",
    "    dict_name = DictCreationFunc.__name__\n",
    "    algo_name = (\n",
    "        \"LSTM\" if AlgoFunc == LSTMpredict.predict else\n",
    "        \"CNN\" if AlgoFunc == CNNpredict.predict else\n",
    "        \"KNN-DTW\" if AlgoFunc == knn_dtw_predict_verbose else\n",
    "        \"XGBoost\" if AlgoFunc == xgboost_feature_predict else\n",
    "        \"Combined\" if AlgoFunc == combined_predict_algo else\n",
    "        \"autre\"\n",
    "    )\n",
    "\n",
    "    for i in range(loop_range):\n",
    "        coord_dict_train, coord_dict_test = DictCreationFunc(df, i + 1)\n",
    "\n",
    "        if AlgoFunc == xgboost_feature_predict:\n",
    "            y_true, y_pred = AlgoFunc(coord_dict_train, coord_dict_test)\n",
    "            total_true.extend(y_true)\n",
    "            total_pred.extend(y_pred)\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            print(f\"\\nExactitude pour {dict_name} {i+1} : {acc:.2%}\")\n",
    "\n",
    "        elif AlgoFunc == combined_predict_algo:\n",
    "            combined_predict_algo.xgb_preds = None\n",
    "            combined_predict_algo.xgb_iter = 0\n",
    "            CNNpredict.df = df\n",
    "            CNNpredict.iter_out = i + 1\n",
    "            CNNpredict.DictFunc = DictCreationFunc\n",
    "            CNNpredict.model = None\n",
    "\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "\n",
    "            for gesture, sequences in coord_dict_test.items():\n",
    "                for seq in sequences:\n",
    "                    pred = AlgoFunc(seq, coord_dict_train, full_dict_test=coord_dict_test)\n",
    "                    if pred is not None:\n",
    "                        y_true.append(gesture)\n",
    "                        y_pred.append(pred)\n",
    "                        total_true.append(gesture)\n",
    "                        total_pred.append(pred)\n",
    "                        print(f\"Vrai label : {gesture} — Prédiction : {pred}\")\n",
    "                    else:\n",
    "                        print(f\"Erreur de prédiction pour le geste {gesture}, séquence ignorée.\")\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            print(f\"\\nExactitude pour {dict_name} {i+1} : {accuracy:.2%}\")\n",
    "\n",
    "        else:\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "\n",
    "            if AlgoFunc == LSTMpredict.predict:\n",
    "                LSTMpredict.df = df\n",
    "                LSTMpredict.iter_out = i + 1\n",
    "                LSTMpredict.DictFunc = DictCreationFunc\n",
    "                LSTMpredict.model = None\n",
    "\n",
    "            if AlgoFunc in [CNNpredict.predict, combined_predict_algo]:\n",
    "                CNNpredict.df = df\n",
    "                CNNpredict.iter_out = i + 1\n",
    "                CNNpredict.DictFunc = DictCreationFunc\n",
    "                CNNpredict.model = None\n",
    "\n",
    "            if AlgoFunc == CNNpredict.predict:\n",
    "                CNNpredict.df = df\n",
    "                CNNpredict.iter_out = i + 1\n",
    "                CNNpredict.DictFunc = DictCreationFunc\n",
    "                CNNpredict.model = None\n",
    "\n",
    "            for gesture, sequences in coord_dict_test.items():\n",
    "                for seq in sequences:\n",
    "                    if AlgoFunc in [LSTMpredict.predict, CNNpredict.predict]:\n",
    "                        pred = AlgoFunc(seq)\n",
    "                    else:\n",
    "                        pred = AlgoFunc(seq, coord_dict_train, k=k)\n",
    "\n",
    "                    if pred is not None:\n",
    "                        y_true.append(gesture)\n",
    "                        y_pred.append(pred)\n",
    "                        total_true.append(gesture)\n",
    "                        total_pred.append(pred)\n",
    "                        print(f\"Vrai label : {gesture} — Prédiction : {pred}\")\n",
    "                    else:\n",
    "                        print(f\"Erreur de prédiction pour le geste {gesture}, séquence ignorée.\")\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            print(f\"\\nExactitude pour {dict_name} {i+1} : {accuracy:.2%}\")\n",
    "\n",
    "        # Erreurs par classe\n",
    "        labels_iter = sorted(set(y_true + y_pred))\n",
    "        cm_iter = confusion_matrix(y_true, y_pred, labels=labels_iter)\n",
    "        errors_by_class = defaultdict(float)\n",
    "        for idx, label in enumerate(labels_iter):\n",
    "            total = cm_iter[idx].sum()\n",
    "            correct = cm_iter[idx, idx]\n",
    "            if total > 0:\n",
    "                error_rate = 1 - (correct / total)\n",
    "                errors_by_class[label] = error_rate\n",
    "                if error_rate > 0.3:\n",
    "                    erreurs_importantes.append(f\"{dict_name} itération {i+1} : {error_rate:.0%} d’erreur sur le geste {label}\")\n",
    "\n",
    "        sorted_errors = sorted(errors_by_class.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_errors = sorted_errors[:3]\n",
    "        all_iteration_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "        all_top_errors.append(top_errors)\n",
    "\n",
    "        print(f\"  ↳ Gestes les plus difficiles à prédire pour {dict_name} {i+1} :\")\n",
    "        for label, err in top_errors:\n",
    "            print(f\"    - Geste {label} : {err:.2%} d’erreur\")\n",
    "\n",
    "    # Résultat\n",
    "    accuracy = accuracy_score(total_true, total_pred)\n",
    "    print(f\"\\n✅ Exactitude globale : {accuracy:.2%}\")\n",
    "\n",
    "    # Matrice de confusion\n",
    "    labels = sorted(set(total_true + total_pred))\n",
    "    cm = confusion_matrix(total_true, total_pred, labels=labels)\n",
    "\n",
    "    full_title = title if title else f\"Matrice de confusion - {algo_name} - Dictionnaire : {dict_name} - Classes : {', '.join(map(str, labels))}\"\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    plt.title(full_title)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        img_name = f\"confusion_{algo_name}_{dict_name}.png\"\n",
    "        plt.savefig(img_name)\n",
    "        print(f\"✅ Image sauvegardée : {img_name}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ecart_type = stdev(all_iteration_accuracies) if len(all_iteration_accuracies) > 1 else 0.0\n",
    "\n",
    "    return total_true, total_pred, [{\n",
    "        \"modèle\": algo_name,\n",
    "        \"split\": dict_name,\n",
    "        \"exactitude\": accuracy,\n",
    "        \"écart-type\": ecart_type,\n",
    "        \"classe la plus confuse\": all_top_errors[-1][0][0] if all_top_errors and all_top_errors[-1] else None,\n",
    "        \"erreurs_>30%\": \"\\n\".join(erreurs_importantes) if erreurs_importantes else \"RAS\"\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testmodel(dict_creation_userout, LSTMpredict.predict, df100, loop_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testmodel(dict_creation_userout, knn_dtw_predict_verbose, df, loop_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testmodel(dict_creation_userout, CNNpredict.predict, df100, loop_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testmodel(dict_creation_userout, xgboost_feature_predict, df100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testmodel(dict_creation_userout, combined_predict_algo, df100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models_and_export(model_configurations, loop_range=10, k=3, excel_filename=\"rapport_global.xlsx\"):\n",
    "    all_reports = []\n",
    "    image_paths = []\n",
    "\n",
    "    for model_name, model_func, dict_func, model_df in model_configurations:\n",
    "        print(f\"\\n🚀 Lancement pour modèle : {model_name} | Split : {dict_func.__name__}\")\n",
    "        try:\n",
    "            total_true, total_pred, report_rows = testmodel(\n",
    "                DictCreationFunc=dict_func,\n",
    "                AlgoFunc=model_func,\n",
    "                df=model_df,\n",
    "                loop_range=loop_range,\n",
    "                k=k,\n",
    "                title=None\n",
    "            )\n",
    "            all_reports.extend(report_rows)\n",
    "\n",
    "            # Ajout du chemin de l'image à intégrer dans Excel\n",
    "            img_name = f\"confusion_{model_name}_{dict_func.__name__}.png\"\n",
    "            image_paths.append(img_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur pour {model_name} avec {dict_func.__name__} : {e}\")\n",
    "\n",
    "    if all_reports:\n",
    "        df_all = pd.DataFrame(all_reports)\n",
    "        with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "            df_all.to_excel(writer, sheet_name='Résultats détaillés', index=False)\n",
    "\n",
    "            # Résumé global\n",
    "            df_summary = df_all.groupby(['modèle', 'split']).agg({\n",
    "                'exactitude': ['mean', 'std'],\n",
    "                'classe la plus confuse': lambda x: x.value_counts().index[0]\n",
    "            }).reset_index()\n",
    "            df_summary.columns = ['Modèle', 'Split', 'Exactitude moyenne', 'Écart-type', 'Classe la plus confuse']\n",
    "            df_summary.to_excel(writer, sheet_name='Résumé global', index=False)\n",
    "\n",
    "        print(f\"\\n📁 Fichier Excel exporté : {excel_filename}\")\n",
    "\n",
    "        # Ajout des images dans le fichier Excel\n",
    "        wb = load_workbook(excel_filename)\n",
    "        for i, img_path in enumerate(image_paths):\n",
    "            try:\n",
    "                ws = wb.create_sheet(title=f\"Confusion {i+1}\")\n",
    "                img = ExcelImage(img_path)\n",
    "                ws.add_image(img, \"A1\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'ajout de l'image {img_path} : {e}\")\n",
    "        wb.save(excel_filename)\n",
    "        print(\"✅ Images ajoutées au fichier Excel.\")\n",
    "        return excel_filename, image_paths\n",
    "    else:\n",
    "        print(\"⚠️ Aucun résultat à exporter.\")\n",
    "        return None, None\n",
    "\n",
    "models_info = [\n",
    "    (\"XGBoost\", xgboost_feature_predict, dict_creation_iterout, df100),(\"XGBoost\", xgboost_feature_predict, dict_creation_userout, df100)\n",
    "    ,(\"LSTM\", LSTMpredict.predict, dict_creation_iterout, df100),(\"LSTM\", LSTMpredict.predict, dict_creation_userout, df100),\n",
    "    (\"CNN\", CNNpredict.predict, dict_creation_iterout, df100),(\"CNN\", CNNpredict.predict, dict_creation_userout, df100),\n",
    "    (\"KNN-DTW\", knn_dtw_predict_verbose, dict_creation_iterout, df),(\"KNN-DTW\", knn_dtw_predict_verbose, dict_creation_userout, df),\n",
    "    (\"Combined\", combined_predict_algo, dict_creation_iterout, df100),(\"Combined\", combined_predict_algo, dict_creation_userout, df100)]\n",
    "\n",
    "excel_path, plot_paths = run_all_models_and_export(models_info)\n",
    "\n",
    "print(f\"Excel sauvegardé : {excel_path}\")\n",
    "print(f\"Graphiques sauvegardés : {plot_paths}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
